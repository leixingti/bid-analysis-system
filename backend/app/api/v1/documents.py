"""æ–‡æ¡£ç®¡ç† API â€” ä¸Šä¼ ã€è§£æã€æŸ¥è¯¢"""
import os
import shutil
from datetime import datetime
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import List, Optional
import logging

from app.core.database import get_db
from app.core.config import settings
from app.models.models import Document, Project
from app.schemas.schemas import DocumentResponse
from app.utils.hash import compute_md5
from app.services.parsing.pdf_parser import PDFParser
from app.services.parsing.docx_parser import DocxParser

router = APIRouter()
logger = logging.getLogger(__name__)


def _doc_to_response(d: Document) -> DocumentResponse:
    """Convert Document model to DocumentResponse, handling fonts_used default."""
    data = {c.name: getattr(d, c.name) for c in d.__table__.columns if c.name != "full_text"}
    if data.get("fonts_used") is None:
        data["fonts_used"] = []
    return DocumentResponse(**data)


@router.post("/upload/{project_id}", response_model=List[DocumentResponse])
async def upload_documents(
    project_id: str,
    files: List[UploadFile] = File(...),
    company_names: Optional[str] = Form(None),
    db: AsyncSession = Depends(get_db)
):
    """
    ä¸Šä¼ æ ‡ä¹¦æ–‡æ¡£ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰

    - project_id: é¡¹ç›®ID
    - files: æ–‡ä»¶åˆ—è¡¨ï¼ˆPDF/DOCXï¼‰
    - company_names: é€—å·åˆ†éš”çš„æŠ•æ ‡å•ä½åç§°ï¼ˆä¸æ–‡ä»¶é¡ºåºå¯¹åº”ï¼‰
    """
    # Verify project exists
    result = await db.execute(select(Project).where(Project.id == project_id))
    project = result.scalar_one_or_none()
    if not project:
        raise HTTPException(status_code=404, detail="é¡¹ç›®ä¸å­˜åœ¨")

    # Parse company names
    companies = []
    if company_names:
        companies = [c.strip() for c in company_names.split(",")]

    uploaded_docs = []
    project_dir = os.path.join(settings.UPLOAD_DIR, project_id)
    os.makedirs(project_dir, exist_ok=True)

    for idx, file in enumerate(files):
        # Validate file type
        ext = os.path.splitext(file.filename)[1].lower()
        if ext not in [".pdf", ".docx", ".doc"]:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file.filename}ï¼Œä»…æ”¯æŒ PDF/DOCX"
            )

        # Save file
        file_path = os.path.join(project_dir, file.filename)
        with open(file_path, "wb") as f:
            content = await file.read()
            f.write(content)

        # Compute hash
        file_hash = compute_md5(file_path)
        file_size = os.path.getsize(file_path)

        company = companies[idx] if idx < len(companies) else ""

        # Create document record
        doc = Document(
            project_id=project_id,
            company_name=company,
            file_name=file.filename,
            file_path=file_path,
            file_type=ext.replace(".", ""),
            file_size=file_size,
            file_hash=file_hash,
        )
        db.add(doc)
        await db.flush()

        # Parse document
        try:
            parsed_data = _parse_document(file_path, ext)
            _apply_parsed_data(doc, parsed_data)
            doc.parsed = 1
            logger.info(f"âœ… æ–‡æ¡£è§£ææˆåŠŸ: {file.filename}, æ–‡æœ¬é•¿åº¦: {doc.text_length}")
        except Exception as e:
            doc.parsed = 2
            logger.error(f"âŒ æ–‡æ¡£è§£æå¤±è´¥ {file.filename}: {e}")

        uploaded_docs.append(doc)

    await db.commit()
    for doc in uploaded_docs:
        await db.refresh(doc)

    return [_doc_to_response(d) for d in uploaded_docs]


@router.get("/{project_id}", response_model=List[DocumentResponse])
async def list_documents(project_id: str, db: AsyncSession = Depends(get_db)):
    """è·å–é¡¹ç›®ä¸‹æ‰€æœ‰æ–‡æ¡£"""
    result = await db.execute(
        select(Document).where(Document.project_id == project_id).order_by(Document.created_at)
    )
    docs = result.scalars().all()
    return [_doc_to_response(d) for d in docs]


@router.get("/detail/{doc_id}", response_model=DocumentResponse)
async def get_document(doc_id: str, db: AsyncSession = Depends(get_db)):
    """è·å–æ–‡æ¡£è¯¦æƒ…"""
    result = await db.execute(select(Document).where(Document.id == doc_id))
    doc = result.scalar_one_or_none()
    if not doc:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")
    return _doc_to_response(doc)


@router.post("/reparse/{doc_id}")
async def reparse_document(doc_id: str, db: AsyncSession = Depends(get_db)):
    """é‡æ–°è§£ææ–‡æ¡£"""
    result = await db.execute(select(Document).where(Document.id == doc_id))
    doc = result.scalar_one_or_none()
    if not doc:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

    try:
        ext = f".{doc.file_type}" if doc.file_type else os.path.splitext(doc.file_name)[1]
        parsed_data = _parse_document(doc.file_path, ext)
        _apply_parsed_data(doc, parsed_data)
        doc.parsed = 1
        await db.commit()
        return {"message": "è§£ææˆåŠŸ", "doc_id": doc_id, "text_length": doc.text_length}
    except Exception as e:
        doc.parsed = 2
        await db.commit()
        raise HTTPException(status_code=500, detail=f"è§£æå¤±è´¥: {str(e)}")


@router.delete("/{doc_id}")
async def delete_document(doc_id: str, db: AsyncSession = Depends(get_db)):
    """åˆ é™¤æ–‡æ¡£"""
    result = await db.execute(select(Document).where(Document.id == doc_id))
    doc = result.scalar_one_or_none()
    if not doc:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

    # Remove file
    if os.path.exists(doc.file_path):
        os.remove(doc.file_path)

    await db.delete(doc)
    await db.commit()
    return {"message": "æ–‡æ¡£å·²åˆ é™¤", "id": doc_id}


# ========== Helper Functions ==========

def _parse_document(file_path: str, ext: str) -> dict:
    """æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©è§£æå™¨"""
    ext = ext.lower()
    if ext in [".pdf"]:
        return PDFParser.parse(file_path)
    elif ext in [".docx"]:
        return DocxParser.parse(file_path)
    else:
        raise ValueError(f"Unsupported file type: {ext}")


def _apply_parsed_data(doc: Document, data: dict):
    """å°†è§£æç»“æœåº”ç”¨åˆ°æ–‡æ¡£æ¨¡å‹"""
    meta = data.get("metadata", {})

    # ğŸ”§ å…³é”®ä¿®å¤ï¼šå…¼å®¹ "full_text" å’Œ "text" ä¸¤ç§ key
    doc.full_text = data.get("full_text") or data.get("text") or ""
    doc.text_length = len(doc.full_text)
    doc.page_count = data.get("page_count", 0)
    doc.fonts_used = data.get("fonts", [])
    doc.format_info = data.get("format_info", {})

    # å…ƒæ•°æ®æ˜ å°„ï¼ˆå…¼å®¹ä¸åŒè§£æå™¨çš„ key å‘½åï¼‰
    doc.meta_author = meta.get("author", "")
    doc.meta_company = meta.get("company", "")
    doc.meta_last_modified_by = meta.get("last_modified_by", "")
    doc.meta_producer = meta.get("producer", "")
    doc.meta_creator = meta.get("creator") or meta.get("application", "")
    doc.meta_software_version = meta.get("software_version") or meta.get("app_version", "")

    # Parse timestampsï¼ˆå…¼å®¹å¤šç§ key å‘½åï¼‰
    for field, keys in [
        ("meta_created_time", ["created_time", "created_date"]),
        ("meta_modified_time", ["modified_time", "modified_date"]),
    ]:
        ts = None
        for key in keys:
            ts = meta.get(key)
            if ts:
                break
        if ts:
            try:
                if isinstance(ts, str) and ts.strip():
                    # å¤„ç† PDF æ ¼å¼çš„æ—¥æœŸ D:20240101120000+08'00'
                    if ts.startswith("D:"):
                        ts_clean = ts[2:16].ljust(14, '0')
                        setattr(doc, field, datetime.strptime(ts_clean, "%Y%m%d%H%M%S"))
                    else:
                        setattr(doc, field, datetime.fromisoformat(ts.replace("Z", "+00:00")))
                elif hasattr(ts, 'year'):  # already a datetime
                    setattr(doc, field, ts)
            except Exception as e:
                logger.warning(f"æ—¶é—´è§£æå¤±è´¥ ({field}={ts}): {e}")

    doc.meta_extra = {k: v for k, v in meta.items()
                      if k not in ["author", "company", "last_modified_by", "producer",
                                   "creator", "software_version", "created_time", "modified_time",
                                   "created_date", "modified_date", "application", "app_version"]}
