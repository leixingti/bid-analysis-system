"""ç»¼åˆé£é™©è¯„åˆ†å¼•æ“ â€” å¤šç»´åº¦åŠ æƒè¯„åˆ† (Phase 1+2)"""
from typing import Dict, Any, List
from app.core.config import settings


class RiskEngine:
    """
    ç»¼åˆé£é™©è¯„åˆ†å¼•æ“
    å°†å„ç»´åº¦æ£€æµ‹ç»“æœåŠ æƒè®¡ç®—ä¸º 0-100 çš„ç»¼åˆé£é™©è¯„åˆ†
    """

    # å„æ£€æµ‹ç»´åº¦æƒé‡ (Phase 1 + Phase 2)
    WEIGHTS = {
        "content_similarity": 0.20,   # æ–‡æœ¬ç›¸ä¼¼åº¦
        "metadata_match": 0.12,       # å…ƒæ•°æ®åŒ¹é…
        "format_match": 0.08,         # æ ¼å¼æŒ‡çº¹
        "timestamp_cluster": 0.10,    # æ—¶é—´æˆ³èšé›†
        "entity_cross": 0.20,         # NER å®ä½“äº¤å‰ (Phase 2)
        "error_pattern": 0.10,        # é”™è¯¯æ¨¡å¼è¯†åˆ« (Phase 2)
        "price_analysis": 0.20,       # æŠ¥ä»·åˆ†æ (Phase 2)
    }

    RISK_THRESHOLDS = {
        "critical": 0.7,
        "high": 0.5,
        "medium": 0.3,
        "low": 0.0,
    }

    @staticmethod
    def compute_project_risk(analysis_results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è®¡ç®—é¡¹ç›®ç»¼åˆé£é™©è¯„åˆ†

        analysis_results: [{
            "type": "content_similarity" | "metadata_match" | "entity_cross" | ...,
            "score": 0.0-1.0,
            "pairs": [...]
        }]
        """
        dimension_scores = {}
        all_alerts = []

        for result in analysis_results:
            rtype = result.get("type", "")
            rscore = result.get("score", 0.0)
            dimension_scores[rtype] = rscore

            for pair in result.get("pairs", []):
                if pair.get("score", 0) > settings.SIMILARITY_THRESHOLD:
                    all_alerts.append({
                        "type": rtype,
                        "score": pair["score"],
                        "company_a": pair.get("company_a", ""),
                        "company_b": pair.get("company_b", ""),
                    })

        # Weighted score
        total_score = 0.0
        total_weight = 0.0
        for dim, weight in RiskEngine.WEIGHTS.items():
            if dim in dimension_scores:
                total_score += dimension_scores[dim] * weight
                total_weight += weight

        normalized_score = total_score / total_weight if total_weight > 0 else 0.0
        risk_score_100 = round(normalized_score * 100, 1)

        risk_level = "low"
        for level, threshold in sorted(RiskEngine.RISK_THRESHOLDS.items(),
                                        key=lambda x: x[1], reverse=True):
            if normalized_score >= threshold:
                risk_level = level
                break

        all_alerts.sort(key=lambda x: x["score"], reverse=True)

        return {
            "risk_score": risk_score_100,
            "risk_level": risk_level,
            "normalized_score": round(normalized_score, 4),
            "dimension_scores": dimension_scores,
            "weights_used": {k: v for k, v in RiskEngine.WEIGHTS.items() if k in dimension_scores},
            "alert_count": len(all_alerts),
            "top_alerts": all_alerts[:10],
            "summary": RiskEngine._generate_summary(risk_level, dimension_scores, all_alerts),
        }

    @staticmethod
    def compute_pair_risk(similarity_score: float, metadata_score: float,
                          format_score: float) -> Dict[str, Any]:
        """è®¡ç®—ä¸¤ä»½æ–‡æ¡£ä¹‹é—´çš„é£é™©"""
        scores = {
            "content_similarity": similarity_score,
            "metadata_match": metadata_score,
            "format_match": format_score,
        }
        weighted = sum(scores.get(d, 0) * w for d, w in RiskEngine.WEIGHTS.items() if d in scores)
        total_w = sum(w for d, w in RiskEngine.WEIGHTS.items() if d in scores)
        normalized = weighted / total_w if total_w > 0 else 0.0

        risk_level = "low"
        for level, threshold in sorted(RiskEngine.RISK_THRESHOLDS.items(),
                                        key=lambda x: x[1], reverse=True):
            if normalized >= threshold:
                risk_level = level
                break

        return {"risk_score": round(normalized * 100, 1), "risk_level": risk_level, "dimension_scores": scores}

    @staticmethod
    def _generate_summary(risk_level: str, scores: Dict[str, float], alerts: List[Dict]) -> str:
        prefixes = {
            "critical": "âš ï¸ æé«˜é£é™©ï¼šå­˜åœ¨æ˜æ˜¾ä¸²æ ‡/å›´æ ‡å«Œç–‘",
            "high": "ğŸ”´ é«˜é£é™©ï¼šæ£€æµ‹åˆ°å¤šé¡¹å¼‚å¸¸æŒ‡æ ‡",
            "medium": "ğŸŸ¡ ä¸­ç­‰é£é™©ï¼šéƒ¨åˆ†æŒ‡æ ‡å¼‚å¸¸éœ€å…³æ³¨",
            "low": "ğŸŸ¢ ä½é£é™©ï¼šæœªæ£€æµ‹åˆ°æ˜æ˜¾å¼‚å¸¸",
        }
        prefix = prefixes.get(risk_level, prefixes["low"])

        details = []
        if scores.get("content_similarity", 0) > 0.2:
            details.append(f"æ–‡æœ¬ç›¸ä¼¼åº¦å¼‚å¸¸({scores['content_similarity']:.0%})")
        if scores.get("metadata_match", 0) > 0.3:
            details.append(f"å…ƒæ•°æ®å…³è”å¼‚å¸¸({scores['metadata_match']:.0%})")
        if scores.get("entity_cross", 0) > 0.3:
            details.append(f"å‘ç°å®ä½“ä¿¡æ¯äº¤å‰æ³„éœ²({scores['entity_cross']:.0%})")
        if scores.get("error_pattern", 0) > 0.3:
            details.append(f"å‘ç°å…±æ€§é”™è¯¯æ¨¡å¼({scores['error_pattern']:.0%})")
        if scores.get("price_analysis", 0) > 0.3:
            details.append(f"æŠ¥ä»·æ•°æ®å­˜åœ¨æ•°å­¦è§„å¾‹({scores['price_analysis']:.0%})")
        if scores.get("format_match", 0) > 0.5:
            details.append(f"æ ¼å¼æŒ‡çº¹é«˜åº¦ä¸€è‡´({scores['format_match']:.0%})")
        if scores.get("timestamp_cluster", 0) > 0.5:
            details.append("æ–‡æ¡£æ—¶é—´æˆ³å¼‚å¸¸èšé›†")

        if details:
            return f"{prefix}ã€‚{'; '.join(details)}ã€‚æ¶‰åŠ {len(alerts)} æ¡é¢„è­¦ã€‚"
        return prefix
